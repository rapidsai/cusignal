{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import cusignal\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sinusodial Signals with N Carriers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On CPU where**:\n",
    "* fs = sample rate of signal\n",
    "* freq = list of carrier frequencies\n",
    "* N = number of points in signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_gen_signal(fs, freq, N):\n",
    "    T = 1/fs\n",
    "    sig = 0\n",
    "    x = np.linspace(0.0, N*(1.0/fs), N)\n",
    "    for f in freq:\n",
    "        sig += np.cos(f*2*cp.pi*x)\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_gen_ensemble(fs, N, num_sig):\n",
    "    sig_ensemble = np.zeros((int(num_sig), int(N)))\n",
    "    for i in range(int(num_sig)):\n",
    "        # random number of carriers in random locations for each signal\n",
    "        freq = 1e6 * np.random.randint(1, 10, np.random.randint(1,5))\n",
    "        sig_ensemble[i,:] = cpu_gen_signal(fs, freq, N)\n",
    "    return sig_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On GPU**\n",
    "\n",
    "Please note, first run of GPU functions includes setting up memory and 'pre-warming' the GPU. For accurate performance and benchmarking each cell is typically run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_gen_signal(fs, freq, N):\n",
    "    T = 1/fs\n",
    "    sig = 0\n",
    "    x = cp.linspace(0.0, N*(1.0/fs), N)\n",
    "    for f in freq:\n",
    "        sig += cp.cos(f*2*cp.pi*x)\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing num carriers for deep learning prediction -- We're even HURTING ourself here with benchmarks!\n",
    "def gpu_gen_ensemble(fs, N, num_sig):\n",
    "    sig_ensemble = cp.zeros((int(num_sig), int(N)))\n",
    "    num_carriers = cp.zeros(int(num_sig))\n",
    "    for i in range(int(num_sig)):\n",
    "        # random number of carriers in random locations for each signal\n",
    "        num_carrier = int(cp.random.randint(1,5))\n",
    "        freq = 1e6 * cp.random.randint(1, 10, num_carrier)\n",
    "        sig_ensemble[i,:] = gpu_gen_signal(fs, freq, N)\n",
    "        num_carriers[i] = num_carrier\n",
    "    return sig_ensemble, num_carriers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a bunch of different signals with arbitrary carrier frequencies. Allow user to select number of signals, sample frequency of the ensemble, and number of points in the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10MHz\n",
    "fs = 10e6\n",
    "\n",
    "# Overwrite\n",
    "num_sig = 2000\n",
    "N = 2**15\n",
    "\n",
    "# Change sample rate so N=2^16\n",
    "up = 2\n",
    "down = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_ensemble = cpu_gen_ensemble(fs, N, num_sig)\n",
    "[gpu_ensemble, num_carriers] = gpu_gen_ensemble(fs, N, num_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample Ensemble - Use Polyphase Resampler to upsample by 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On CPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.14 s, sys: 528 ms, total: 3.66 s\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resample_cpu_ensemble = signal.resample_poly(cpu_ensemble, up, down, axis=1, window='flattop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 279 ms, sys: 16.3 ms, total: 296 ms\n",
      "Wall time: 294 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resample_gpu_ensemble = cusignal.resample_poly(gpu_ensemble, up, down, axis=1, window='flattop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Periodogram with Flattop Filter over Each Row of Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On CPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.32 s, sys: 2.2 s, total: 5.52 s\n",
      "Wall time: 5.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cf, cPxx_den = signal.periodogram(resample_cpu_ensemble, fs, 'flattop', scaling='spectrum', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 199 ms, sys: 68.7 ms, total: 268 ms\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gf, gPxx_den = cusignal.periodogram(resample_gpu_ensemble, fs, 'flattop', scaling='spectrum', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On CPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.semilogy(cf, cPxx_den[0,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.semilogy(cp.asnumpy(gf), cp.asnumpy(gPxx_den[0,:]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move to PyTorch to try to 'predict' number of carriers in signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to ensure PyTorch is installed.\n",
    "# PyTorch is intentionally excluded from our Docker images due to its size.\n",
    "# Alternatively, the docker image can be run with the following variable:\n",
    "#     docker run -e EXTRA_CONDA_PACKAGES=\"-c pytorch pytorch\"...\n",
    "\n",
    "#!conda install -y -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#90 percent of dataset for training\n",
    "training_idx_max = int(0.9*gPxx_den.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gPxx_den = gPxx_den.astype(cp.float32)\n",
    "num_carriers = num_carriers.astype(cp.int64)\n",
    "\n",
    "# Zero copy memory from cupy to DLPack to Torch\n",
    "x = torch.as_tensor(gPxx_den[0:training_idx_max,:], device=device)\n",
    "y = torch.as_tensor(num_carriers[0:training_idx_max], device=device)\n",
    "\n",
    "# Test\n",
    "x_t = torch.as_tensor(gPxx_den[training_idx_max:gPxx_den.shape[0],:], device=device)\n",
    "y_t = torch.as_tensor(num_carriers[training_idx_max:gPxx_den.shape[0]], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of possible carriers\n",
    "output_size = 10\n",
    "\n",
    "epochs = 75\n",
    "batch_size = 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.l1 = nn.Linear(x.shape[1], 1500)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l3 = nn.Linear(1500, 750)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l5 = nn.Linear(750, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l5(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "net = Network().to(device)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.5)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i in range(0, x.shape[0], batch_size):\n",
    "        x_mini = x[i:i + batch_size] \n",
    "        y_mini = y[i:i + batch_size] \n",
    "        \n",
    "        x_var = Variable(x_mini)\n",
    "        y_var = Variable(y_mini)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        net_out = net(x_var)\n",
    "        \n",
    "        loss = F.nll_loss(net_out, y_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            loss_log.append(loss.data)\n",
    "        \n",
    "    print('Epoch: {} - Loss: {:.6f}'.format(e, loss.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measure Inference Accuracy on Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "for i in range(x_t.shape[0]):\n",
    "    pred = net(x_t[i,:].expand(1,-1)).argmax()\n",
    "    correct += pred.eq(y_t[i].view_as(pred)).sum().item()\n",
    "\n",
    "print('Accuracy: ', 100. * correct / x_t.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'net': Network(),\n",
    "             'state_dict': net.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()}\n",
    "\n",
    "torch.save(checkpoint,\"E2E_sig_proc.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('E2E_sig_proc.pt')\n",
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate New Signal and Look at Inferencing Power**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_carrier = 2\n",
    "freq = 1e6 * cp.random.randint(1, 10, num_carrier)\n",
    "sig = gpu_gen_signal(fs, freq, N)\n",
    "r_sig = cusignal.resample_poly(sig, up, down, window='flattop')\n",
    "f, Pxx = cusignal.periodogram(r_sig, fs, 'flattop', scaling='spectrum')\n",
    "\n",
    "x = torch.as_tensor(Pxx.astype(cp.float32), device=device)\n",
    "\n",
    "pred_num_carrier = net(x.expand(1,-1)).argmax().item()\n",
    "\n",
    "print(pred_num_carrier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}