{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting and Demodulating FM Radio Stations and Using NeMo for Speech to Text Transcription\n",
    "The following demonstration shows how to:\n",
    "1. Use [simplesoapy](https://github.com/xmikos/simplesoapy) to capture I/Q signals from an [rtlsdr](https://www.rtl-sdr.com/about-rtl-sdr/)\n",
    "2. Move I/Q samples collected with the radio to the GPU for processing\n",
    "3. Use cuSignal to visualize the power spectrum of the signal on the GPU\n",
    "4. Use cuSignal and CuPy to demodulate the FM radio station and generate a .wav output\n",
    "5. Use NVIDIA's [NeMo](https://github.com/NVIDIA/NeMo) ASR toolkit to generate a speech-to-text transcription of the recorded .wav with a pre-trained QuartzNet and Citrinet model\n",
    "6. Use NeMo's Machine Translation models to translate transcipt from English to French\n",
    "\n",
    "This tutorial is focused on offline processing where we use the rtlsdr to fill a large buffer with I/Q samples (e.g. 15 seconds of recorded data). We then run all downstream processing on this single signal. Other notebooks will demonstrate online signal processing, where we're demodulating smaller buffers, in real time, and running speech to text transcription in real time. This tutorial is primarily meant to familarize developers with the signal processing and software defined radio workflows and tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [First-Run Only] Environment Setup\n",
    "The below cell installs pyrtlsdr, the Nemo ASR toolkit, QuartzNet model, and required dependencies. You only need to run this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apt dependencies\n",
    "!apt-get update && apt-get install -y sox libsndfile1 ffmpeg\n",
    "\n",
    "# conda dependencies\n",
    "!mamba install -y soapysdr-module-rtlsdr\n",
    "\n",
    "# pip dependencies\n",
    "!pip install unidecode simplesoapy\n",
    "\n",
    "# source install and configure NeMo\n",
    "!python -m pip install \"git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[all]\"\n",
    "!mkdir configs\n",
    "!wget -P configs/ \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/asr/conf/config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU Powered Libraries\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "# GPU Powered Libraries\n",
    "import cupy as cp\n",
    "import cusignal\n",
    "\n",
    "# RTL-SDR Support\n",
    "import simplesoapy\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Nemo Speech to Text\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "# Wav Tools\n",
    "from scipy.io import wavfile\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup SDR to Capture Over the Air Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr = simplesoapy.SoapyDevice('driver=rtlsdr')\n",
    "sdr.sample_rate = 2.56e6 # Radio sample rate (Hz)\n",
    "sdr.freq = 88.5e6 # Center frequency (Hz)\n",
    "sdr.gain = 40\n",
    "\n",
    "buffer_size = sdr.sample_rate # Use 1 second of data as the buffer size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data from RTL-SDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read 15 seconds of signal data tuned to 88.5MHz [WAMU-DC](https://wamu.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_collect = 15 #seconds\n",
    "\n",
    "# Create shared CPU/GPU output buffer\n",
    "smem_signal = cusignal.get_shared_mem(int(len_collect * sdr.sample_rate), dtype=np.complex64)\n",
    "\n",
    "# Start radio\n",
    "sdr.start_stream()\n",
    "\n",
    "# Read samples from radio and place in output buffer\n",
    "sdr.read_stream_into_buffer(smem_signal)\n",
    "\n",
    "# Switch Context to GPU\n",
    "gpu_signal = cp.asarray(smem_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Periodogram to Visualize Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, Pxx_den = cusignal.periodogram(gpu_signal, sdr.sample_rate, window='hamm', scaling='spectrum', return_onesided=False)\n",
    "plt.semilogy(cp.asnumpy(cp.fft.fftshift(f/1e4)), cp.asnumpy(cp.fft.fftshift(Pxx_den)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FM Demodulate Radio Signal\n",
    "Without demodulation, your favorite radio station sounds something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaudio = cusignal.resample_poly(gpu_signal, 1, sdr.sample_rate//48000, window='hamm')\n",
    "wavfile.write('sig.wav', rate=48000, data=abs(cp.asnumpy(gaudio)).astype(cp.float32))\n",
    "IPython.display.Audio('sig.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With demodulation, we can 'decode' the radio collection to hear music, speech, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdemod_sig = cusignal.fm_demod(gpu_signal)\n",
    "\n",
    "# Reduce sample rate from radio fs to wav fs\n",
    "gaudio = cusignal.resample_poly(gdemod_sig, 1, sdr.sample_rate//48000, window='hamm')\n",
    "wavfile.write('demod_sig.wav', rate=48000, data=cp.asnumpy(gaudio).astype(cp.float32))\n",
    "IPython.display.Audio('demod_sig.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection to SDR and Clean Up\n",
    "sdr.stop_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nemo ASR - Obtain Transcript of Recording\n",
    "Use pre-trained QuartzNet and Citrinet models to run AI inferencing on demodulated radio collection to obtain an English transcription. Citrinet is a significnatly larger model than QuartzNet and tends to have better accuracy. With NeMo, one can see the ease of substituting different pre-trained language models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quartznet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = quartznet.transcribe([\"demod_sig.wav\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quartznet Transcription Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcription[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citrinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citrinet = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(model_name=\"stt_en_citrinet_1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = citrinet.transcribe([\"demod_sig.wav\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transcription Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcription[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nemo - Machine Translation - Translate Transcription from English to French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.nlp.models import MTEncDecModel\n",
    "\n",
    "# English to French\n",
    "model = MTEncDecModel.from_pretrained(\"nmt_en_fr_transformer12x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = model.translate([transcription], source_lang=\"en\", target_lang=\"fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Translation Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translations[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
